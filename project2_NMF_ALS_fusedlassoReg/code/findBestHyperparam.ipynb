{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dcd9963-43bf-4a0b-a5bb-5e315954e7cc",
   "metadata": {},
   "source": [
    "# 0. Downloaded all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02405de9-9c04-4108-ad76-60b88759646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import pyBigWig\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from glob import glob\n",
    "from numba import njit #jit without python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca51ebb7-5399-4435-8cf9-26ec55f31e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate the function parser\n",
    "args = argparse.Namespace(\n",
    "    bw_dir=\"/ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10\",\n",
    "    chromosome_number=\"chr10\",\n",
    "    start_pos=1000000,\n",
    "    end_pos=1500000,\n",
    "    k=15\n",
    ")\n",
    "\n",
    "args.bw_dir\n",
    "args.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2f1a94-f587-4827-a324-4a3ee7d23bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(f'{args.bw_dir}/*.bw')\n",
    "# print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da3ef9-e961-4c68-b44a-75665060c28f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0.1. Check the BW files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc3f243-ba5b-4ea3-874f-c191f76ca501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/GATA1.K562.rawSignal.hg18.chr10.bw\n",
      "=== Header ===\n",
      "{'version': 4, 'nLevels': 10, 'nBasesCovered': 149842891, 'minVal': 0, 'maxVal': 1612, 'sumData': 119698649, 'sumSquared': 1190975642}\n",
      "\n",
      "=== Chromosomes ===\n",
      "{'chr10': 135374737}\n",
      "\n",
      "=== Is BigWig? ===\n",
      "True\n",
      "\n",
      "=== Stats for chr10:1,000,000-1,500,000 ===\n",
      "Mean: [1.1236287922458716]\n",
      "Max: [16.0]\n",
      "Min: [0.0]\n",
      "Std: [1.390962952903734]\n",
      "Coverage: [1.2373589710844124]\n",
      "\n",
      "=== First 10 intervals ===\n",
      "(999863, 1000367, 0.0)\n",
      "(1000367, 1000421, 1.0)\n",
      "(1000421, 1000467, 2.0)\n",
      "(1000467, 1000487, 3.0)\n",
      "(1000487, 1000499, 2.0)\n",
      "(1000499, 1000508, 3.0)\n",
      "(1000508, 1000514, 4.0)\n",
      "(1000514, 1000525, 5.0)\n",
      "(1000525, 1000587, 6.0)\n",
      "(1000587, 1000598, 5.0)\n",
      "\n",
      "=== 1_000_000-1_000_010 numpy format ===\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(files[1]) # ChIP-seq\n",
    "with pyBigWig.open(files[1]) as bw:\n",
    "    # 1. File header (metadata)\n",
    "    print(\"=== Header ===\")\n",
    "    print(bw.header())\n",
    "    \n",
    "    # 2. Chromosomes and their sizes\n",
    "    print(\"\\n=== Chromosomes ===\")\n",
    "    print(bw.chroms())\n",
    "    \n",
    "    # 3. Check if it's a BigWig (vs BigBed)\n",
    "    print(\"\\n=== Is BigWig? ===\")\n",
    "    print(bw.isBigWig())\n",
    "    \n",
    "    # 4. Summary statistics for a region\n",
    "    print(\"\\n=== Stats for chr10:1,000,000-1,500,000 ===\")\n",
    "    print(\"Mean:\", bw.stats(\"chr10\", 1_000_000, 1_500_000, type=\"mean\"))\n",
    "    print(\"Max:\",  bw.stats(\"chr10\", 1_000_000, 1_500_000, type=\"max\"))\n",
    "    print(\"Min:\",  bw.stats(\"chr10\", 1_000_000, 1_500_000, type=\"min\"))\n",
    "    print(\"Std:\",  bw.stats(\"chr10\", 1_000_000, 1_500_000, type=\"std\"))\n",
    "    print(\"Coverage:\", bw.stats(\"chr10\", 1_000_000, 1_500_000, type=\"coverage\"))\n",
    "    \n",
    "    # 5. Get intervals (sparse representation: start, end, value)\n",
    "    print(\"\\n=== First 10 intervals ===\")\n",
    "    intervals = bw.intervals(\"chr10\", 1_000_000, 1_500_000)\n",
    "    for iv in intervals[:10]:\n",
    "        print(iv)  # (start, end, value)\n",
    "\n",
    "    # 6. get the numpy version\n",
    "    print(\"\\n=== 1_000_000-1_000_010 numpy format ===\")\n",
    "    print(bw.values(\"chr10\", 1000000, 1000010, numpy=True)) #same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70187bbb-7cf9-4f88-8b9b-8091e56532a7",
   "metadata": {},
   "source": [
    "# 1. Create the matrix for factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "675d3e8d-5065-435c-8745-b392a1fa3151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/SRF.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 1 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/GATA1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 2 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Max.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 3 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/CTCF.K562.Iyer.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 4 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cFos.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 5 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K4me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 6 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K4me2.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 7 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/JunD.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 8 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/NFE2.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 9 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/FAIRE.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 10 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_8WG16.K562.Snyder.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 11 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Rad21.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 12 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/XRCC4.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 13 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K36me3.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 14 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cMyc.K562.Iyer.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 15 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_CTD4H8.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 16 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K9me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 17 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/CTCF.K562.Bernstein.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 18 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/ZNF263.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 19 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/DNaseI.K562.Crawford.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 20 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_8WG16.K562.Myers.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 21 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cMyc.K562.Snyder.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 22 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K9ac.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 23 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K27me3.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 24 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/DNaseI.K562.Stam.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 25 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K27ac.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 26 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cJun.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 27 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H4K20me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 28 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/GABP.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 29 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/NRSF.K562.rawSignal.hg18.chr10.bw\n"
     ]
    }
   ],
   "source": [
    "# Place holder for the matrix\n",
    "row = args.end_pos - args.start_pos\n",
    "col = len(files)\n",
    "Y = np.empty((row, col), dtype=np.float32)\n",
    "# print(Y)\n",
    "\n",
    "# Build the matrix\n",
    "for idx, fname in enumerate(files):\n",
    "    print('\\n', idx, fname)\n",
    "    # IMPLEMENT -- use pyBigWig to access the .bw files\n",
    "    \t# use args.chromosome_number to access the correct chromosome\n",
    "    \t# use args.start_pos and args.end_pos for the start and end position of the chromosome\n",
    "    with pyBigWig.open(fname) as bw:\n",
    "        f_val = bw.values(args.chromosome_number, args.start_pos, args.end_pos, numpy=True)\n",
    "        f_val = f_val.astype(np.float32, copy=False) #change type\n",
    "        #deal with NaN, apply any other transformations\n",
    "        np.nan_to_num(f_val, copy=False, #in place\n",
    "                      nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        #non-negative transformation\n",
    "        f_val[f_val < 0] = 0\n",
    "        #assign in place\n",
    "        Y[:, idx] = f_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72a0ba3-b4f6-43eb-97c9-5ee0a7910952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 30)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a740e216-d33b-485a-8ded-a8b94fdd4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### setup proximity operator using the provided code ###########'\n",
    "# Implement numba\n",
    "@njit(cache=True)  # nopython mode by default; cache=True avoids recompiling between runs\n",
    "def pyprox_dp(y, lam): #return theta - the smoothed input vector\n",
    "    n = len(y)\n",
    "    if n == 0:\n",
    "        return y.copy()\n",
    "\n",
    "    theta = np.zeros_like(y)    \n",
    "    # Take care of a few trivial cases\n",
    "    if n == 1 or lam == 0:\n",
    "        for i in range(n):\n",
    "            theta[i] = y[i]\n",
    "        return theta\n",
    "            \n",
    "  # These are used to store the derivative of the\n",
    "  # piecewise quadratic function of interest\n",
    "    afirst = 0.0\n",
    "    alast = 0.0\n",
    "    bfirst = 0.0\n",
    "    blast = 0.0\n",
    "    \n",
    "    x = np.zeros(2*n, dtype=y.dtype)\n",
    "    a = np.zeros(2*n, dtype=y.dtype)\n",
    "    b = np.zeros(2*n, dtype=y.dtype)\n",
    "  \n",
    "    l = 0\n",
    "    r = 0\n",
    "\n",
    "  # These are the knots of the back-pointers\n",
    "    tm = np.zeros(n-1, dtype=y.dtype)\n",
    "    tp = np.zeros(n-1, dtype=y.dtype)\n",
    "\n",
    "  # We step through the first iteration manually\n",
    "    tm[0] = -lam+y[0]\n",
    "    tp[0] = lam+y[0]\n",
    "    l = n-1\n",
    "    r = n\n",
    "    x[l] = tm[0]\n",
    "    x[r] = tp[0]\n",
    "    a[l] = 1\n",
    "    b[l] = -y[0]+lam\n",
    "    a[r] = -1\n",
    "    b[r] = y[0]+lam\n",
    "    afirst = 1\n",
    "    bfirst = -lam-y[1]\n",
    "    alast = -1\n",
    "    blast = -lam+y[1]\n",
    "\n",
    "  # Now iterations 2 through n-1\n",
    "    lo = 0\n",
    "    hi = 0\n",
    "    alo = 0.0\n",
    "    blo = 0.0\n",
    "    ahi = 0.0\n",
    "    bhi = 0.0\n",
    "    \n",
    "    for k in range(1,n-1):\n",
    "        # Compute lo: step up from l until the\n",
    "        # derivative is greater than -lam\n",
    "        alo = afirst\n",
    "        blo = bfirst\n",
    "        for lo in range(l,r+1):            \n",
    "            if alo*x[lo]+blo > -lam: break\n",
    "\n",
    "            alo += a[lo]\n",
    "            blo += b[lo]\n",
    "        else:\n",
    "            lo = r+1\n",
    "        \n",
    "        # Compute the negative knot\n",
    "\n",
    "        tm[k] = (-lam-blo)/alo\n",
    "        l = lo-1\n",
    "        x[l] = tm[k]\n",
    "\n",
    "        # Compute hi: step down from r until the\n",
    "        # derivative is less than lam\n",
    "        ahi = alast\n",
    "        bhi = blast\n",
    "        for hi in range(r,l-1,-1):\n",
    "            if -ahi*x[hi]-bhi < lam: break\n",
    "            ahi += a[hi]\n",
    "            bhi += b[hi]\n",
    "        else:\n",
    "            hi = l-1        \n",
    "\n",
    "        # Compute the positive knot\n",
    "        tp[k] = (lam+bhi)/(-ahi)\n",
    "        r = hi+1\n",
    "        x[r] = tp[k]\n",
    "\n",
    "        # Update a and b\n",
    "        a[l] = alo\n",
    "        b[l] = blo+lam\n",
    "        a[r] = ahi\n",
    "        b[r] = bhi+lam\n",
    "\n",
    "        afirst = 1\n",
    "        bfirst = -lam-y[k+1]\n",
    "        alast = -1\n",
    "        blast = -lam+y[k+1]\n",
    "        \n",
    "  # Compute the last coefficient: this is where \n",
    "  # the function has zero derivative\n",
    "\n",
    "    alo = afirst\n",
    "    blo = bfirst\n",
    "    for lo in range(l, r+1):\n",
    "        if alo*x[lo]+blo > 0: break\n",
    "        alo += a[lo]\n",
    "        blo += b[lo]\n",
    "  \n",
    "    theta[n-1] = -blo/alo\n",
    "\n",
    "  # Compute the rest of the coefficients, by the\n",
    "  # back-pointers\n",
    "    for k in range(n-2,-1,-1):\n",
    "        if theta[k+1]>tp[k]:\n",
    "            theta[k] = tp[k]\n",
    "        elif theta[k+1]<tm[k]:\n",
    "            theta[k] = tm[k]\n",
    "        else:\n",
    "            theta[k] = theta[k+1]\n",
    "  \n",
    "\n",
    "    return theta\n",
    "\n",
    "# Ensure numba is applied to contiguous array\n",
    "def fused_lasso(y, lam):\n",
    "    y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "    return pyprox_dp(y, np.float32(lam))\n",
    "\n",
    "# # Use bins to the rows or the genomic regions to speed up -> later recover the dimension by replication the same value within each bin\n",
    "# def fused_lasso_binned(y, lam, bin_size=20):\n",
    "#     if lam <= 0.0:\n",
    "#         return y\n",
    "#     if bin_size <= 1 or y.size < bin_size:\n",
    "#         return fused_lasso(y, lam)\n",
    "\n",
    "#     y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "#     # length of original vector\n",
    "#     n = y.size\n",
    "#     # number of bins\n",
    "#     m = (n + bin_size - 1) // bin_size\n",
    "#     # padding to correspond to the binned range\n",
    "#     pad = m * bin_size - n\n",
    "\n",
    "#     if pad > 0:\n",
    "#         yp = np.empty(m * bin_size, dtype=np.float32)\n",
    "#         yp[:n] = y\n",
    "#         yp[n:] = y[-1]  # edge pad - last element value\n",
    "#     else:\n",
    "#         yp = y\n",
    "\n",
    "#     # reshape and get the mean over the bin\n",
    "#     yb = yp.reshape(m, bin_size).mean(axis=1).astype(np.float32, copy=False)\n",
    "#     # compute over the bin\n",
    "#     tb = fused_lasso(yb, lam)\n",
    "#     return np.repeat(tb, bin_size)[:n] # trim the extra values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aedd49-f543-474f-9974-17a8413d7804",
   "metadata": {},
   "source": [
    "# 2. NMF pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0183ec0a-3c27-4854-b9ca-3a979ae5c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "def init_H(Y,k,SEED=1221):\n",
    "\t# initialize H - nneg!\n",
    "\t# can be a random initialization or using the randomized_svd from sklearn\n",
    "    _, D, Vt = randomized_svd(M=Y, n_components=k, random_state=SEED)\n",
    "    \n",
    "    # Use scaled version of loading H (give better initialization signal)\n",
    "    #   convert D from (k,) to (k,1) -> strech to match Vt (k, n_features) -> (k, n_feature) -> element-wise\n",
    "    H = (D[:,None] * Vt).astype(np.float32, copy=False)\n",
    "    \n",
    "    # nneg transformation\n",
    "    H[H<0] = 0.0\n",
    "    H += np.float32(1e-6) # random number to prevent exact zero\n",
    "\n",
    "    return H\n",
    "\n",
    "# NMF\n",
    "# NMF\n",
    "def NMF_FL(Y, k, num_iter=50, l2penalty=1, fl_lambda=1, tol=1e-4):\n",
    "    H = init_H(Y,k,SEED=1221)\n",
    "    print('\\n','Completed randomized_svd H initialization...')\n",
    "\n",
    "    # Create diagonal offset D\n",
    "    #   if l2penalty is small all this does is make the matrix invertible\n",
    "    D = np.eye(k, dtype=np.float32) * np.float32(l2penalty)\n",
    "    Y = np.asarray(Y, dtype=np.float32)\n",
    "\n",
    "    # warm up JIT once (avoids compile cost inside iteration 0)\n",
    "    _ = fused_lasso(np.zeros(16, dtype=np.float32), np.float32(fl_lambda))\n",
    "\n",
    "    # store error and improvment for early stop\n",
    "    ynorm = np.linalg.norm(Y, 'fro') + 1e-12\n",
    "    prev_rel_err = None\n",
    "    ## store bad impr patience before break\n",
    "    patience = 10\n",
    "    bad = 0\n",
    "\n",
    "    for n in range(num_iter):\n",
    "        if n % 50 == 0:\n",
    "            print('\\n', f'==== Starting iteration {n} ====')\n",
    "        # Update W\n",
    "        # $W \\leftarrow Y H^T (H H^T + D)^{-1}$\n",
    "        A = (H @ H.T + D) #(k,k)\n",
    "        B = (Y @ H.T)     #(nrow,k)\n",
    "        \n",
    "        # W = B @ np.linalg.inv(A) # slow indicated by GPT\n",
    "        W = np.linalg.solve(A.T, B.T).T.astype(np.float32, copy=False)\n",
    "        # np.linalg.solve() above is the same as A^T @ X = B^T \n",
    "        # -> X = (A^T)^(-1) @ B^T \n",
    "        # -> Xt= ((A^T)^(-1) @ B^T)^T\n",
    "        #      = B @ inv(A.T).T\n",
    "        #      = B @ inv(A)\n",
    "\n",
    "        # Set negative elements of W to 0\n",
    "        W[W < 0.0] = 0.0\n",
    "\n",
    "        # apply fused lasso\n",
    "        for j in range(k): #cols of W\n",
    "            W[:, j] = fused_lasso(W[:, j], fl_lambda)\n",
    "            # W[:, j] = fused_lasso_binned(W[:, j], fl_lambda, bin_size=20)\n",
    "        W[W < 0.0] = 0.0\n",
    "        \n",
    "        # Update H\n",
    "        C = (W.T@W) + D\n",
    "        E = (W.T@Y)\n",
    "        # H = inv(C)@E\n",
    "        H = np.linalg.solve(C, E).astype(np.float32, copy=False)\n",
    "        # C @ X = E\n",
    "        # X = inv(C)@E\n",
    "\n",
    "        # Set negative elements of H to 0\n",
    "        H[H < 0.0] = 0.0\n",
    "\n",
    "        #early stopping?\n",
    "        rel_err = np.linalg.norm(Y - W@H, 'fro') / ynorm #Frobenius norm\n",
    "        if prev_rel_err is None:\n",
    "            impr = np.nan\n",
    "        else:\n",
    "            impr = (prev_rel_err-rel_err) / max(prev_rel_err, 1e-12) #prevent 0 div; we want impr > 0\n",
    "\n",
    "        #log\n",
    "        if n % 50 == 0:\n",
    "            print(f\"rel_err={rel_err:.6f} impr={impr:.3e}\")\n",
    "\n",
    "        #eval\n",
    "        if prev_rel_err is not None and impr <= 1e-6:\n",
    "            bad += 1\n",
    "        else:\n",
    "            bad = 0\n",
    "        \n",
    "        if bad >= patience:\n",
    "            print(f\"Stop: no improvement for {patience} iterations (iter {n})\")\n",
    "            break\n",
    "\n",
    "        if prev_rel_err is not None and impr > 0.0 and impr < tol:\n",
    "            print(f\"Converged at iteration {n}\")\n",
    "            break\n",
    "\n",
    "        #update error\n",
    "        prev_rel_err = rel_err\n",
    "\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d94864-5318-4ded-87a7-2d32c1d030a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "049ff206-7364-4215-809e-4d8c16b88013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "\n",
      " ==== Starting iteration 50 ====\n"
     ]
    }
   ],
   "source": [
    "W, H = NMF_FL(Y[:1000,:], k=2, num_iter=100, l2penalty=1, fl_lambda=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f05d0b00-2b54-4bec-a85a-d09d82a8562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcbbbd-eb22-4be4-8c9d-dc861d077b91",
   "metadata": {},
   "source": [
    "# 3. Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "476d42f8-2c11-48a9-8232-9290d02d7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k, (num_iter,) l2penalty, and fl_lambda are all hyperparameters that should be tuned to maximize correlation with genes\n",
    "\n",
    "def load_realAnnot(annotation_bw_path, chrom, start, end): \n",
    "    with pyBigWig.open(annotation_bw_path) as bw:\n",
    "        g = bw.values(chrom, start, end, numpy=True)\n",
    "    g = g.astype(np.float32, copy=False)\n",
    "    np.nan_to_num(g, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return g\n",
    "\n",
    "def eval_pearson_corr(a, b):\n",
    "    a = np.asarray(a, dtype=np.float32)\n",
    "    b = np.asarray(b, dtype=np.float32)\n",
    "    if a.shape[0] != b.shape[0]:\n",
    "        raise ValueError(\"Vectors must have the same length\")\n",
    "    \n",
    "    a_bar = a - a.mean()\n",
    "    b_bar = b - b.mean()\n",
    "    sasb = (np.linalg.norm(a_bar) * np.linalg.norm(b_bar)) + 1e-12\n",
    "    r = float(np.dot(a_bar, b_bar) / sasb)\n",
    "    return r\n",
    "\n",
    "def find_maxAbs_pearson_corr(W, g):\n",
    "    best = -1.0\n",
    "    best_feature = -1\n",
    "    for j in range(W.shape[1]):\n",
    "        r = eval_pearson_corr(W[:, j], g)\n",
    "        if abs(r) > best:\n",
    "            best = abs(r)\n",
    "            best_j = j\n",
    "    return best, best_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3041625c-edf1-4a57-aa05-f2f87d22452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.178971 impr=nan\n",
      "Stop: no improvement for 10 iterations (iter 15)\n",
      "l2=1e-06 fl=0.1 score=0.2388 best_j=12\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=2.457342 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.685736 impr=2.695e-01\n",
      "\n",
      " ==== Starting iteration 100 ====\n",
      "rel_err=1.002941 impr=1.268e-01\n",
      "\n",
      " ==== Starting iteration 150 ====\n",
      "rel_err=1.826213 impr=-3.244e-02\n",
      "\n",
      " ==== Starting iteration 200 ====\n",
      "rel_err=0.796681 impr=-7.977e-01\n",
      "\n",
      " ==== Starting iteration 250 ====\n",
      "rel_err=1.738892 impr=5.932e-01\n",
      "l2=1e-06 fl=10 score=0.3843 best_j=3\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.177890 impr=nan\n",
      "Stop: no improvement for 10 iterations (iter 15)\n",
      "l2=0.01 fl=0.1 score=0.1381 best_j=12\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=1.147567 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=1.112577 impr=-1.341e+00\n",
      "\n",
      " ==== Starting iteration 100 ====\n",
      "rel_err=0.231963 impr=-7.561e-02\n",
      "\n",
      " ==== Starting iteration 150 ====\n",
      "rel_err=0.184922 impr=4.170e-02\n",
      "\n",
      " ==== Starting iteration 200 ====\n",
      "rel_err=0.220310 impr=7.279e-04\n",
      "\n",
      " ==== Starting iteration 250 ====\n",
      "rel_err=0.246983 impr=-6.362e-03\n",
      "l2=0.01 fl=10 score=0.5775 best_j=8\n",
      "BEST: (0.5774577487339557, 0.01, 10.0)\n"
     ]
    }
   ],
   "source": [
    "# # simulate the function parser\n",
    "# args = argparse.Namespace(\n",
    "#     bw_dir=\"/ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10\",\n",
    "#     chromosome_number=\"chr10\",\n",
    "#     start_pos=1000000,\n",
    "#     end_pos=1500000,\n",
    "#     k=15\n",
    "# )\n",
    "\n",
    "g = load_realAnnot('/ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/Annotation_hg18.Gene.bw', args.chromosome_number, args.start_pos, args.end_pos) \n",
    "\n",
    "l2_grid = [1e-6, 1e-2]\n",
    "fl_grid = [0.1, 10.0]\n",
    "\n",
    "best = (-1.0, None, None)\n",
    "\n",
    "for l2 in l2_grid:\n",
    "    for fl in fl_grid:\n",
    "        W, H = NMF_FL(Y, args.k, num_iter=300, l2penalty=l2, fl_lambda=fl, tol=1e-4)\n",
    "        score, best_j = find_maxAbs_pearson_corr(W, g)\n",
    "        print(f\"l2={l2:g} fl={fl:g} score={score:.4f} best_j={best_j}\")\n",
    "        if score > best[0]:\n",
    "            best = (score, l2, fl)\n",
    "\n",
    "print(\"BEST:\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e200450-18d4-427d-886e-9f2296d043b7",
   "metadata": {},
   "source": [
    "Best: `l2=0.01 fl=10 score=0.5775 best_j=8`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f4748-0ea0-44bc-b904-3f502d851f62",
   "metadata": {},
   "source": [
    "## Search 2 - short Chr10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce856673-7550-4152-bc0c-627b9aa968ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/SRF.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 1 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/GATA1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 2 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Max.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 3 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/CTCF.K562.Iyer.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 4 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cFos.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 5 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K4me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 6 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K4me2.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 7 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/JunD.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 8 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/NFE2.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 9 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/FAIRE.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 10 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_8WG16.K562.Snyder.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 11 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Rad21.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 12 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/XRCC4.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 13 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K36me3.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 14 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cMyc.K562.Iyer.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 15 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_CTD4H8.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 16 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K9me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 17 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/CTCF.K562.Bernstein.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 18 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/ZNF263.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 19 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/DNaseI.K562.Crawford.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 20 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_8WG16.K562.Myers.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 21 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cMyc.K562.Snyder.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 22 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K9ac.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 23 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K27me3.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 24 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/DNaseI.K562.Stam.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 25 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K27ac.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 26 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cJun.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 27 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H4K20me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 28 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/GABP.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 29 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/NRSF.K562.rawSignal.hg18.chr10.bw\n",
      "(500000, 30)\n"
     ]
    }
   ],
   "source": [
    "for idx, fname in enumerate(files):\n",
    "    print('\\n', idx, fname)\n",
    "    # IMPLEMENT -- use pyBigWig to access the .bw files\n",
    "    \t# use args.chromosome_number to access the correct chromosome\n",
    "    \t# use args.start_pos and args.end_pos for the start and end position of the chromosome\n",
    "    with pyBigWig.open(fname) as bw:\n",
    "        f_val = bw.values(args.chromosome_number, args.start_pos, args.end_pos, numpy=True)\n",
    "        f_val = f_val.astype(np.float32, copy=False) #change type\n",
    "        #deal with NaN, apply any other transformations\n",
    "        np.nan_to_num(f_val, copy=False, #in place\n",
    "                      nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        #non-negative transformation\n",
    "        f_val[f_val < 0] = 0\n",
    "        #assign in place\n",
    "        Y[:, idx] = f_val\n",
    "print(Y.shape)\n",
    "\n",
    "Y = np.log1p(Y).astype(np.float32, copy=False)              # compress huge peaks\n",
    "col_norm = np.linalg.norm(Y, axis=0) + 1e-12               # equalize tracks\n",
    "Y = (Y / col_norm).astype(np.float32, copy=False)\n",
    "\n",
    "########### setup proximity operator using the provided code ###########\n",
    "# Implement numba\n",
    "@njit(cache=True)  # nopython mode by default; cache=True avoids recompiling between runs\n",
    "def pyprox_dp(y, lam): #return theta - the smoothed input vector\n",
    "    n = len(y)\n",
    "    if n == 0:\n",
    "        return y.copy()\n",
    "\n",
    "    theta = np.zeros_like(y)    \n",
    "    # Take care of a few trivial cases\n",
    "    if n == 1 or lam == 0:\n",
    "        for i in range(n):\n",
    "            theta[i] = y[i]\n",
    "        return theta\n",
    "            \n",
    "  # These are used to store the derivative of the\n",
    "  # piecewise quadratic function of interest\n",
    "    afirst = 0.0\n",
    "    alast = 0.0\n",
    "    bfirst = 0.0\n",
    "    blast = 0.0\n",
    "    \n",
    "    x = np.zeros(2*n, dtype=y.dtype)\n",
    "    a = np.zeros(2*n, dtype=y.dtype)\n",
    "    b = np.zeros(2*n, dtype=y.dtype)\n",
    "  \n",
    "    l = 0\n",
    "    r = 0\n",
    "\n",
    "  # These are the knots of the back-pointers\n",
    "    tm = np.zeros(n-1, dtype=y.dtype)\n",
    "    tp = np.zeros(n-1, dtype=y.dtype)\n",
    "\n",
    "  # We step through the first iteration manually\n",
    "    tm[0] = -lam+y[0]\n",
    "    tp[0] = lam+y[0]\n",
    "    l = n-1\n",
    "    r = n\n",
    "    x[l] = tm[0]\n",
    "    x[r] = tp[0]\n",
    "    a[l] = 1\n",
    "    b[l] = -y[0]+lam\n",
    "    a[r] = -1\n",
    "    b[r] = y[0]+lam\n",
    "    afirst = 1\n",
    "    bfirst = -lam-y[1]\n",
    "    alast = -1\n",
    "    blast = -lam+y[1]\n",
    "\n",
    "  # Now iterations 2 through n-1\n",
    "    lo = 0\n",
    "    hi = 0\n",
    "    alo = 0.0\n",
    "    blo = 0.0\n",
    "    ahi = 0.0\n",
    "    bhi = 0.0\n",
    "    \n",
    "    for k in range(1,n-1):\n",
    "        # Compute lo: step up from l until the\n",
    "        # derivative is greater than -lam\n",
    "        alo = afirst\n",
    "        blo = bfirst\n",
    "        for lo in range(l,r+1):            \n",
    "            if alo*x[lo]+blo > -lam: break\n",
    "\n",
    "            alo += a[lo]\n",
    "            blo += b[lo]\n",
    "        else:\n",
    "            lo = r+1\n",
    "        \n",
    "        # Compute the negative knot\n",
    "\n",
    "        tm[k] = (-lam-blo)/alo\n",
    "        l = lo-1\n",
    "        x[l] = tm[k]\n",
    "\n",
    "        # Compute hi: step down from r until the\n",
    "        # derivative is less than lam\n",
    "        ahi = alast\n",
    "        bhi = blast\n",
    "        for hi in range(r,l-1,-1):\n",
    "            if -ahi*x[hi]-bhi < lam: break\n",
    "            ahi += a[hi]\n",
    "            bhi += b[hi]\n",
    "        else:\n",
    "            hi = l-1        \n",
    "\n",
    "        # Compute the positive knot\n",
    "        tp[k] = (lam+bhi)/(-ahi)\n",
    "        r = hi+1\n",
    "        x[r] = tp[k]\n",
    "\n",
    "        # Update a and b\n",
    "        a[l] = alo\n",
    "        b[l] = blo+lam\n",
    "        a[r] = ahi\n",
    "        b[r] = bhi+lam\n",
    "\n",
    "        afirst = 1\n",
    "        bfirst = -lam-y[k+1]\n",
    "        alast = -1\n",
    "        blast = -lam+y[k+1]\n",
    "        \n",
    "  # Compute the last coefficient: this is where \n",
    "  # the function has zero derivative\n",
    "\n",
    "    alo = afirst\n",
    "    blo = bfirst\n",
    "    for lo in range(l, r+1):\n",
    "        if alo*x[lo]+blo > 0: break\n",
    "        alo += a[lo]\n",
    "        blo += b[lo]\n",
    "  \n",
    "    theta[n-1] = -blo/alo\n",
    "\n",
    "  # Compute the rest of the coefficients, by the\n",
    "  # back-pointers\n",
    "    for k in range(n-2,-1,-1):\n",
    "        if theta[k+1]>tp[k]:\n",
    "            theta[k] = tp[k]\n",
    "        elif theta[k+1]<tm[k]:\n",
    "            theta[k] = tm[k]\n",
    "        else:\n",
    "            theta[k] = theta[k+1]\n",
    "  \n",
    "\n",
    "    return theta\n",
    "\n",
    "# Ensure numba is applied to contiguous array\n",
    "def fused_lasso(y, lam):\n",
    "    y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "    return pyprox_dp(y, np.float32(lam))\n",
    "\n",
    "# Use bins to the rows or the genomic regions to speed up -> later recover the dimension by replication the same value within each bin\n",
    "def fused_lasso_binned(y, lam, bin_size=20):\n",
    "    if lam <= 0.0:\n",
    "        return y\n",
    "    if bin_size <= 1 or y.size < bin_size:\n",
    "        return fused_lasso(y, lam)\n",
    "\n",
    "    y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "    # length of original vector\n",
    "    n = y.size\n",
    "    # number of bins\n",
    "    m = (n + bin_size - 1) // bin_size\n",
    "    # padding to correspond to the binned range\n",
    "    pad = m * bin_size - n\n",
    "\n",
    "    if pad > 0:\n",
    "        yp = np.empty(m * bin_size, dtype=np.float32)\n",
    "        yp[:n] = y\n",
    "        yp[n:] = y[-1]  # edge pad - last element value\n",
    "    else:\n",
    "        yp = y\n",
    "\n",
    "    # reshape and get the mean over the bin\n",
    "    yb = yp.reshape(m, bin_size).mean(axis=1).astype(np.float32, copy=False)\n",
    "    # compute over the bin\n",
    "    tb = fused_lasso(yb, lam)\n",
    "    return np.repeat(tb, bin_size)[:n] # trim the extra values\n",
    "\n",
    "\n",
    "########### NMF pipeline ###########\n",
    "# Initialize\n",
    "def init_H(Y,k,SEED=1221):\n",
    "\t# initialize H - nneg!\n",
    "\t# can be a random initialization or using the randomized_svd from sklearn\n",
    "    _, D, Vt = randomized_svd(M=Y, n_components=k, random_state=SEED)\n",
    "    \n",
    "    # Use scaled version of loading H (give better initialization signal)\n",
    "    #   convert D from (k,) to (k,1) -> strech to match Vt (k, n_features) -> (k, n_feature) -> element-wise\n",
    "    H = (D[:,None] * Vt).astype(np.float32, copy=False)\n",
    "    \n",
    "    # nneg transformation\n",
    "    H[H<0] = 0.0\n",
    "    H += np.float32(1e-6) # random number to prevent exact zero\n",
    "\n",
    "    return H\n",
    "\n",
    "# NMF\n",
    "def NMF_FL(Y, k, num_iter=50, l2penalty=1, fl_lambda=1, tol=1e-4):\n",
    "    H = init_H(Y,k,SEED=1221)\n",
    "    print('\\n','Completed randomized_svd H initialization...')\n",
    "\n",
    "    # Create diagonal offset D\n",
    "    #   if l2penalty is small all this does is make the matrix invertible\n",
    "    D = np.eye(k, dtype=np.float32) * np.float32(l2penalty)\n",
    "    Y = np.asarray(Y, dtype=np.float32)\n",
    "\n",
    "    # warm up JIT once (avoids compile cost inside iteration 0)\n",
    "    _ = fused_lasso(np.zeros(16, dtype=np.float32), np.float32(fl_lambda))\n",
    "\n",
    "    # store error and improvment for early stop\n",
    "    ynorm = np.linalg.norm(Y, 'fro') + 1e-12\n",
    "    prev_rel_err = None\n",
    "    ## store bad impr patience/steps before break\n",
    "    patience = 10\n",
    "    bad = 0\n",
    "\n",
    "    ## speed up - binning & less usage of fl\n",
    "    L = Y.shape[0]\n",
    "    if L >= 1000000:\n",
    "        bin_size = 50\n",
    "        fl_every = 5\n",
    "    else:\n",
    "        bin_size = 20\n",
    "        fl_every = 3\n",
    "    \n",
    "    for n in range(num_iter):\n",
    "        if n % 50 == 0:\n",
    "            print('\\n', f'==== Starting iteration {n} ====')\n",
    "        # Update W\n",
    "        # $W \\leftarrow Y H^T (H H^T + D)^{-1}$\n",
    "        A = (H @ H.T + D) #(k,k)\n",
    "        B = (Y @ H.T)     #(nrow,k)\n",
    "        \n",
    "        # W = B @ np.linalg.inv(A) # slow indicated by GPT\n",
    "        W = np.linalg.solve(A.T, B.T).T.astype(np.float32, copy=False)\n",
    "        # np.linalg.solve() above is the same as A^T @ X = B^T \n",
    "        # -> X = (A^T)^(-1) @ B^T \n",
    "        # -> Xt= ((A^T)^(-1) @ B^T)^T\n",
    "        #      = B @ inv(A.T).T\n",
    "        #      = B @ inv(A)\n",
    "\n",
    "        # Set negative elements of W to 0\n",
    "        W[W < 0.0] = 0.0\n",
    "\n",
    "        # apply fused lasso\n",
    "        if fl_lambda > 0.0 and (n % fl_every == 0):\n",
    "            for j in range(k): #cols of W\n",
    "                # W[:, j] = fused_lasso(W[:, j], fl_lambda)\n",
    "                W[:, j] = fused_lasso_binned(W[:, j], fl_lambda, bin_size=bin_size)\n",
    "            W[W < 0.0] = 0.0\n",
    "        \n",
    "        # Update H\n",
    "        C = (W.T@W) + D\n",
    "        E = (W.T@Y)\n",
    "        # H = inv(C)@E\n",
    "        H = np.linalg.solve(C, E).astype(np.float32, copy=False)\n",
    "        # C @ X = E\n",
    "        # X = inv(C)@E\n",
    "\n",
    "        # Set negative elements of H to 0\n",
    "        H[H < 0.0] = 0.0\n",
    "\n",
    "        #early stopping?\n",
    "        rel_err = np.linalg.norm(Y - W@H, 'fro') / ynorm #Frobenius norm\n",
    "        if prev_rel_err is None:\n",
    "            impr = np.nan\n",
    "        else:\n",
    "            impr = (prev_rel_err-rel_err) / max(prev_rel_err, 1e-12) #prevent 0 div; we want impr > 0\n",
    "\n",
    "        #log\n",
    "        if n % 50 == 0:\n",
    "            print(f\"rel_err={rel_err:.6f} impr={impr:.3e}\")\n",
    "\n",
    "        #eval\n",
    "        if prev_rel_err is not None and impr <= 1e-6:\n",
    "            bad += 1\n",
    "        else:\n",
    "            bad = 0\n",
    "        \n",
    "        if bad >= patience:\n",
    "            print(f\"Stop: no improvement for {patience} iterations (iter {n})\")\n",
    "            break\n",
    "\n",
    "        if prev_rel_err is not None and impr > 0.0 and impr < tol:\n",
    "            print(f\"Converged at iteration {n}\")\n",
    "            break\n",
    "\n",
    "        #update error\n",
    "        prev_rel_err = rel_err\n",
    "\n",
    "    return W, H\n",
    "\n",
    "\n",
    "########### RUN1 - Hyperparameter Tuning Using Grid Search (comment out later) ###########\n",
    "# k, (num_iter,) l2penalty, and fl_lambda are all hyperparameters that should be tuned to maximize correlation with genes\n",
    "\n",
    "def load_realAnnot(annotation_bw_path, chrom, start, end): \n",
    "    with pyBigWig.open(annotation_bw_path) as bw:\n",
    "        g = bw.values(chrom, start, end, numpy=True)\n",
    "    g = g.astype(np.float32, copy=False)\n",
    "    np.nan_to_num(g, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return g\n",
    "\n",
    "def eval_pearson_corr(a, b):\n",
    "    a = np.asarray(a, dtype=np.float32)\n",
    "    b = np.asarray(b, dtype=np.float32)\n",
    "    if a.shape[0] != b.shape[0]:\n",
    "        raise ValueError(\"Vectors must have the same length\")\n",
    "    \n",
    "    a_bar = a - a.mean()\n",
    "    b_bar = b - b.mean()\n",
    "    sasb = (np.linalg.norm(a_bar) * np.linalg.norm(b_bar)) + 1e-12\n",
    "    r = float(np.dot(a_bar, b_bar) / sasb)\n",
    "    return r\n",
    "\n",
    "def find_maxAbs_pearson_corr(W, g):\n",
    "    best = -1.0\n",
    "    best_feature = -1\n",
    "    for j in range(W.shape[1]):\n",
    "        r = eval_pearson_corr(W[:, j], g)\n",
    "        if abs(r) > best:\n",
    "            best = abs(r)\n",
    "            best_j = j\n",
    "    return best, best_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f5b96ac-e8e7-4424-a208-14036e569a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.535642 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.382423 impr=1.516e-04\n",
      "Converged at iteration 61\n",
      "l2=1e-06 fl=0 score=0.1085 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=1.412057 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.568544 impr=2.839e-02\n",
      "l2=1e-06 fl=0.1 score=0.3765 best_j=3\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=3.449979 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.560827 impr=4.679e-01\n",
      "l2=1e-06 fl=0.3 score=0.4097 best_j=12\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=20.802456 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.604912 impr=1.670e-02\n",
      "l2=1e-06 fl=1 score=0.4132 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=26.271727 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.586456 impr=3.728e-01\n",
      "l2=1e-06 fl=3 score=0.3431 best_j=11\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=17.269002 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.559611 impr=1.275e-01\n",
      "l2=1e-06 fl=10 score=0.2816 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.535398 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.382199 impr=1.857e-04\n",
      "Converged at iteration 65\n",
      "l2=0.0001 fl=0 score=0.1082 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=1.378949 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.497198 impr=8.284e-02\n",
      "l2=0.0001 fl=0.1 score=0.4588 best_j=13\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=2.466866 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.545570 impr=5.075e-02\n",
      "l2=0.0001 fl=0.3 score=0.4145 best_j=2\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=3.723881 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.521546 impr=1.065e-01\n",
      "l2=0.0001 fl=1 score=0.6563 best_j=13\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=4.755611 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.554819 impr=9.601e-02\n",
      "l2=0.0001 fl=3 score=0.3214 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=2.079870 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.587084 impr=7.494e-01\n",
      "l2=0.0001 fl=10 score=0.3190 best_j=4\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.519210 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.382308 impr=1.387e-04\n",
      "Converged at iteration 64\n",
      "l2=0.01 fl=0 score=0.1075 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.753488 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.421054 impr=1.105e-01\n",
      "l2=0.01 fl=0.1 score=0.4418 best_j=7\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.751188 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.484660 impr=1.038e-01\n",
      "l2=0.01 fl=0.3 score=0.6944 best_j=5\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.755151 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.529510 impr=5.146e-02\n",
      "l2=0.01 fl=1 score=0.4433 best_j=9\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.737030 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.542695 impr=4.372e-01\n",
      "l2=0.01 fl=3 score=0.4116 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.740799 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.640417 impr=5.577e-01\n",
      "l2=0.01 fl=10 score=0.0000 best_j=3\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.494387 impr=nan\n",
      "Converged at iteration 36\n",
      "l2=0.1 fl=0 score=0.1071 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.681625 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.430334 impr=1.728e-01\n",
      "l2=0.1 fl=0.1 score=0.5206 best_j=7\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.702744 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.504758 impr=1.138e-01\n",
      "l2=0.1 fl=0.3 score=0.5770 best_j=11\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.723189 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.571799 impr=2.141e-02\n",
      "l2=0.1 fl=1 score=0.3878 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.733315 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.623679 impr=2.986e-03\n",
      "Converged at iteration 53\n",
      "l2=0.1 fl=3 score=0.1215 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.741160 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.624086 impr=1.971e-03\n",
      "l2=0.1 fl=10 score=0.3883 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.729690 impr=nan\n",
      "Converged at iteration 9\n",
      "l2=1 fl=0 score=0.1316 best_j=7\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.802493 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.678153 impr=-6.844e-04\n",
      "l2=1 fl=0.1 score=0.2674 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.811316 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.677945 impr=-1.155e-03\n",
      "l2=1 fl=0.3 score=0.3496 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.814342 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.678023 impr=-1.385e-03\n",
      "l2=1 fl=1 score=0.4053 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.821329 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.678111 impr=-1.453e-03\n",
      "l2=1 fl=3 score=0.4193 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.821329 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.678053 impr=-1.781e-03\n",
      "l2=1 fl=10 score=0.0000 best_j=7\n",
      "BEST: (0.6943908209525683, 0.01, 0.3)\n"
     ]
    }
   ],
   "source": [
    "##### Grid Search + Eval #####\n",
    "g = load_realAnnot('/ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/Annotation_hg18.Gene.bw', args.chromosome_number, args.start_pos, args.end_pos) \n",
    "\n",
    "l2_grid = [1e-6, 1e-4, 1e-2, 1e-1, 1.0]\n",
    "fl_grid = [0.0, 0.1, 0.3, 1.0, 3.0, 10.0]\n",
    "\n",
    "best = (-1.0, None, None)\n",
    "\n",
    "for l2 in l2_grid:\n",
    "    for fl in fl_grid:\n",
    "        W, H = NMF_FL(Y, args.k, num_iter=100, l2penalty=l2, fl_lambda=fl, tol=1e-4)\n",
    "        score, best_j = find_maxAbs_pearson_corr(W, g)\n",
    "        print(f\"l2={l2:g} fl={fl:g} score={score:.4f} best_j={best_j}\")\n",
    "        if score > best[0]:\n",
    "            best = (score, l2, fl)\n",
    "\n",
    "print(\"BEST:\", best)\n",
    "\n",
    "#   Best: l2=0.01 fl=10 score=0.5775 best_j=8\n",
    "\n",
    "# ########### RUN2 - Production ###########\n",
    "# W, H = NMF_FL(Y, args.k, num_iter=100, l2penalty=0.01, fl_lambda=10.0, tol=1e-4)\n",
    "\n",
    "# np.save(args.output_file, W, allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920f524-9832-42ee-b0a5-92057947c242",
   "metadata": {},
   "source": [
    "```\n",
    "BEST: (0.6943908209525683, 0.01, 0.3)\n",
    "l2=0.1 fl=0.3 score=0.5770 best_j=11\n",
    "l2=0.0001 fl=1 score=0.6563 best_j=13\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609a521-459d-4f5e-ab92-9101760384d8",
   "metadata": {},
   "source": [
    "## Search 3 - long Chr10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "061656a1-a37c-42f6-8224-81415db7ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/CTCF.K562.Bernstein.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 1 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/CTCF.K562.Iyer.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 2 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/DNaseI.K562.Crawford.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 3 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/DNaseI.K562.Stam.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 4 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/FAIRE.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 5 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/GABP.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 6 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/GATA1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 7 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K27ac.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 8 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K27me3.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 9 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K36me3.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 10 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K4me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 11 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K4me2.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 12 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K9ac.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 13 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H3K9me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 14 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/H4K20me1.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 15 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/JunD.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 16 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Max.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 17 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/NFE2.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 18 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/NRSF.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 19 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_8WG16.K562.Myers.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 20 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_8WG16.K562.Snyder.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 21 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Pol2_CTD4H8.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 22 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/Rad21.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 23 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/SRF.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 24 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/XRCC4.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 25 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/ZNF263.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 26 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cFos.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 27 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cJun.K562.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 28 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cMyc.K562.Iyer.rawSignal.hg18.chr10.bw\n",
      "\n",
      " 29 /ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10/cMyc.K562.Snyder.rawSignal.hg18.chr10.bw\n",
      "(10000000, 30)\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.563247 impr=nan\n",
      "Converged at iteration 32\n",
      "l2=1e-06 fl=0 score=0.2297 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=1.343024 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=1.172045 impr=-1.017e+00\n",
      "l2=1e-06 fl=0.1 score=0.3119 best_j=3\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=3.109769 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=1.280134 impr=-1.066e+00\n",
      "l2=1e-06 fl=0.3 score=0.2379 best_j=9\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=3.064274 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=1.619320 impr=-1.769e+00\n",
      "l2=1e-06 fl=1 score=0.2403 best_j=9\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=22.551290 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=1.907231 impr=-1.906e+00\n",
      "Converged at iteration 58\n",
      "l2=1e-06 fl=3 score=0.2567 best_j=2\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.854911 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.764711 impr=-1.973e-01\n",
      "Converged at iteration 73\n",
      "l2=1e-06 fl=10 score=0.2567 best_j=3\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.563221 impr=nan\n",
      "Converged at iteration 34\n",
      "l2=0.0001 fl=0 score=0.2294 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=1.176159 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.954912 impr=-6.968e-01\n",
      "l2=0.0001 fl=0.1 score=0.3410 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=4.075878 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=1.189116 impr=-1.185e+00\n",
      "l2=0.0001 fl=0.3 score=0.2532 best_j=7\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=2.477634 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.962462 impr=-7.118e-01\n",
      "l2=0.0001 fl=1 score=0.3147 best_j=2\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=13.151892 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=1.151424 impr=-8.258e-01\n",
      "Converged at iteration 59\n",
      "l2=0.0001 fl=3 score=0.2567 best_j=7\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.804203 impr=nan\n",
      "Converged at iteration 33\n",
      "l2=0.0001 fl=10 score=0.2567 best_j=3\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.560973 impr=nan\n",
      "Converged at iteration 33\n",
      "l2=0.01 fl=0 score=0.2290 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.753907 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.768655 impr=-5.092e-01\n",
      "l2=0.01 fl=0.1 score=0.3190 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.763739 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.821976 impr=-5.966e-01\n",
      "l2=0.01 fl=0.3 score=0.3235 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.773008 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.812960 impr=-5.466e-01\n",
      "l2=0.01 fl=1 score=0.3244 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.788144 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.803021 impr=-4.768e-01\n",
      "l2=0.01 fl=3 score=0.3316 best_j=7\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.770424 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.771262 impr=-3.753e-01\n",
      "l2=0.01 fl=10 score=0.2162 best_j=8\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.557663 impr=nan\n",
      "Converged at iteration 40\n",
      "l2=0.1 fl=0 score=0.2277 best_j=1\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.740151 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.733932 impr=-4.387e-01\n",
      "l2=0.1 fl=0.1 score=0.3227 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.753115 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.744197 impr=-4.497e-01\n",
      "l2=0.1 fl=0.3 score=0.3288 best_j=6\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.764908 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.761932 impr=-4.330e-01\n",
      "l2=0.1 fl=1 score=0.2884 best_j=3\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.770547 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.764017 impr=-4.089e-01\n",
      "l2=0.1 fl=3 score=0.2135 best_j=2\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.770930 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.770788 impr=-3.565e-01\n",
      "l2=0.1 fl=10 score=0.2210 best_j=8\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.752039 impr=nan\n",
      "Converged at iteration 12\n",
      "l2=1 fl=0 score=0.2566 best_j=7\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.825063 impr=nan\n",
      "Converged at iteration 14\n",
      "l2=1 fl=0.1 score=0.2571 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.830544 impr=nan\n",
      "\n",
      " ==== Starting iteration 50 ====\n",
      "rel_err=0.772636 impr=-9.734e-02\n",
      "l2=1 fl=0.3 score=0.2568 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.834545 impr=nan\n",
      "Converged at iteration 4\n",
      "l2=1 fl=1 score=0.2568 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.838341 impr=nan\n",
      "Converged at iteration 4\n",
      "l2=1 fl=3 score=0.2567 best_j=0\n",
      "\n",
      " Completed randomized_svd H initialization...\n",
      "\n",
      " ==== Starting iteration 0 ====\n",
      "rel_err=0.838901 impr=nan\n",
      "Converged at iteration 3\n",
      "l2=1 fl=10 score=0.2567 best_j=5\n",
      "BEST: (0.34095103514069625, 0.0001, 0.1)\n"
     ]
    }
   ],
   "source": [
    "# simulate the function parser\n",
    "args = argparse.Namespace(\n",
    "    bw_dir=\"/ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/chr10\",\n",
    "    chromosome_number=\"chr10\",\n",
    "    start_pos=1000000,\n",
    "    end_pos=11000000,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "files = sorted(glob(f'{args.bw_dir}/*.bw'))\n",
    "\n",
    "# Place holder for the matrix\n",
    "row = args.end_pos - args.start_pos\n",
    "col = len(files)\n",
    "Y = np.empty((row, col), dtype=np.float32)\n",
    "# print(Y)\n",
    "########### Build the matrix ###########\n",
    "for idx, fname in enumerate(files):\n",
    "    print('\\n', idx, fname)\n",
    "    # IMPLEMENT -- use pyBigWig to access the .bw files\n",
    "    \t# use args.chromosome_number to access the correct chromosome\n",
    "    \t# use args.start_pos and args.end_pos for the start and end position of the chromosome\n",
    "    with pyBigWig.open(fname) as bw:\n",
    "        f_val = bw.values(args.chromosome_number, args.start_pos, args.end_pos, numpy=True)\n",
    "        f_val = f_val.astype(np.float32, copy=False) #change type\n",
    "        #deal with NaN, apply any other transformations\n",
    "        np.nan_to_num(f_val, copy=False, #in place\n",
    "                      nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        #non-negative transformation\n",
    "        f_val[f_val < 0] = 0\n",
    "        #assign in place\n",
    "        Y[:, idx] = f_val\n",
    "print(Y.shape)\n",
    "\n",
    "########### preprocessing to improve correlation ###########\n",
    "Y = np.log1p(Y).astype(np.float32, copy=False)  # compress huge peaks\n",
    "col_norm = np.linalg.norm(Y, axis=0) + 1e-12    # normalize different tracks\n",
    "Y = (Y / col_norm).astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "########### setup proximity operator using the provided code ###########\n",
    "# Implement numba\n",
    "@njit(cache=True)  # nopython mode by default; cache=True avoids recompiling between runs\n",
    "def pyprox_dp(y, lam): #return theta - the smoothed input vector\n",
    "    n = len(y)\n",
    "    if n == 0:\n",
    "        return y.copy()\n",
    "\n",
    "    theta = np.zeros_like(y)    \n",
    "    # Take care of a few trivial cases\n",
    "    if n == 1 or lam == 0:\n",
    "        for i in range(n):\n",
    "            theta[i] = y[i]\n",
    "        return theta\n",
    "            \n",
    "  # These are used to store the derivative of the\n",
    "  # piecewise quadratic function of interest\n",
    "    afirst = 0.0\n",
    "    alast = 0.0\n",
    "    bfirst = 0.0\n",
    "    blast = 0.0\n",
    "    \n",
    "    x = np.zeros(2*n, dtype=y.dtype)\n",
    "    a = np.zeros(2*n, dtype=y.dtype)\n",
    "    b = np.zeros(2*n, dtype=y.dtype)\n",
    "  \n",
    "    l = 0\n",
    "    r = 0\n",
    "\n",
    "  # These are the knots of the back-pointers\n",
    "    tm = np.zeros(n-1, dtype=y.dtype)\n",
    "    tp = np.zeros(n-1, dtype=y.dtype)\n",
    "\n",
    "  # We step through the first iteration manually\n",
    "    tm[0] = -lam+y[0]\n",
    "    tp[0] = lam+y[0]\n",
    "    l = n-1\n",
    "    r = n\n",
    "    x[l] = tm[0]\n",
    "    x[r] = tp[0]\n",
    "    a[l] = 1\n",
    "    b[l] = -y[0]+lam\n",
    "    a[r] = -1\n",
    "    b[r] = y[0]+lam\n",
    "    afirst = 1\n",
    "    bfirst = -lam-y[1]\n",
    "    alast = -1\n",
    "    blast = -lam+y[1]\n",
    "\n",
    "  # Now iterations 2 through n-1\n",
    "    lo = 0\n",
    "    hi = 0\n",
    "    alo = 0.0\n",
    "    blo = 0.0\n",
    "    ahi = 0.0\n",
    "    bhi = 0.0\n",
    "    \n",
    "    for k in range(1,n-1):\n",
    "        # Compute lo: step up from l until the\n",
    "        # derivative is greater than -lam\n",
    "        alo = afirst\n",
    "        blo = bfirst\n",
    "        for lo in range(l,r+1):            \n",
    "            if alo*x[lo]+blo > -lam: break\n",
    "\n",
    "            alo += a[lo]\n",
    "            blo += b[lo]\n",
    "        else:\n",
    "            lo = r+1\n",
    "        \n",
    "        # Compute the negative knot\n",
    "\n",
    "        tm[k] = (-lam-blo)/alo\n",
    "        l = lo-1\n",
    "        x[l] = tm[k]\n",
    "\n",
    "        # Compute hi: step down from r until the\n",
    "        # derivative is less than lam\n",
    "        ahi = alast\n",
    "        bhi = blast\n",
    "        for hi in range(r,l-1,-1):\n",
    "            if -ahi*x[hi]-bhi < lam: break\n",
    "            ahi += a[hi]\n",
    "            bhi += b[hi]\n",
    "        else:\n",
    "            hi = l-1        \n",
    "\n",
    "        # Compute the positive knot\n",
    "        tp[k] = (lam+bhi)/(-ahi)\n",
    "        r = hi+1\n",
    "        x[r] = tp[k]\n",
    "\n",
    "        # Update a and b\n",
    "        a[l] = alo\n",
    "        b[l] = blo+lam\n",
    "        a[r] = ahi\n",
    "        b[r] = bhi+lam\n",
    "\n",
    "        afirst = 1\n",
    "        bfirst = -lam-y[k+1]\n",
    "        alast = -1\n",
    "        blast = -lam+y[k+1]\n",
    "        \n",
    "  # Compute the last coefficient: this is where \n",
    "  # the function has zero derivative\n",
    "\n",
    "    alo = afirst\n",
    "    blo = bfirst\n",
    "    for lo in range(l, r+1):\n",
    "        if alo*x[lo]+blo > 0: break\n",
    "        alo += a[lo]\n",
    "        blo += b[lo]\n",
    "  \n",
    "    theta[n-1] = -blo/alo\n",
    "\n",
    "  # Compute the rest of the coefficients, by the\n",
    "  # back-pointers\n",
    "    for k in range(n-2,-1,-1):\n",
    "        if theta[k+1]>tp[k]:\n",
    "            theta[k] = tp[k]\n",
    "        elif theta[k+1]<tm[k]:\n",
    "            theta[k] = tm[k]\n",
    "        else:\n",
    "            theta[k] = theta[k+1]\n",
    "  \n",
    "\n",
    "    return theta\n",
    "\n",
    "# Ensure numba is applied to contiguous array\n",
    "def fused_lasso(y, lam):\n",
    "    y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "    return pyprox_dp(y, np.float32(lam))\n",
    "\n",
    "# Use bins to the rows or the genomic regions to speed up -> later recover the dimension by replication the same value within each bin\n",
    "def fused_lasso_binned(y, lam, bin_size=20):\n",
    "    if lam <= 0.0:\n",
    "        return y\n",
    "    if bin_size <= 1 or y.size < bin_size:\n",
    "        return fused_lasso(y, lam)\n",
    "\n",
    "    y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "    # length of original vector\n",
    "    n = y.size\n",
    "    # number of bins\n",
    "    m = (n + bin_size - 1) // bin_size\n",
    "    # padding to correspond to the binned range\n",
    "    pad = m * bin_size - n\n",
    "\n",
    "    if pad > 0:\n",
    "        yp = np.empty(m * bin_size, dtype=np.float32)\n",
    "        yp[:n] = y\n",
    "        yp[n:] = y[-1]  # edge pad - last element value\n",
    "    else:\n",
    "        yp = y\n",
    "\n",
    "    # reshape and get the mean over the bin\n",
    "    yb = yp.reshape(m, bin_size).mean(axis=1).astype(np.float32, copy=False)\n",
    "    # compute over the bin\n",
    "    tb = fused_lasso(yb, lam)\n",
    "    return np.repeat(tb, bin_size)[:n] # trim the extra values\n",
    "\n",
    "\n",
    "########### NMF pipeline ###########\n",
    "# Initialize\n",
    "def init_H(Y,k,SEED=1221):\n",
    "\t# initialize H - nneg!\n",
    "\t# can be a random initialization or using the randomized_svd from sklearn\n",
    "    _, D, Vt = randomized_svd(M=Y, n_components=k, random_state=SEED)\n",
    "    \n",
    "    # Use scaled version of loading H (give better initialization signal)\n",
    "    #   convert D from (k,) to (k,1) -> strech to match Vt (k, n_features) -> (k, n_feature) -> element-wise\n",
    "    H = (D[:,None] * Vt).astype(np.float32, copy=False)\n",
    "    \n",
    "    # nneg transformation\n",
    "    H[H<0] = 0.0\n",
    "    H += np.float32(1e-6) # random number to prevent exact zero\n",
    "\n",
    "    return H\n",
    "\n",
    "# NMF\n",
    "def NMF_FL(Y, k, num_iter=50, l2penalty=1, fl_lambda=1, tol=1e-4):\n",
    "    H = init_H(Y,k,SEED=1221)\n",
    "    print('\\n','Completed randomized_svd H initialization...')\n",
    "\n",
    "    # Create diagonal offset D\n",
    "    #   if l2penalty is small all this does is make the matrix invertible\n",
    "    D = np.eye(k, dtype=np.float32) * np.float32(l2penalty)\n",
    "    Y = np.asarray(Y, dtype=np.float32)\n",
    "\n",
    "    # warm up JIT once (avoids compile cost inside iteration 0)\n",
    "    _ = fused_lasso(np.zeros(16, dtype=np.float32), np.float32(fl_lambda))\n",
    "\n",
    "    # store error and improvment for early stop\n",
    "    ynorm = np.linalg.norm(Y, 'fro') + 1e-12\n",
    "    prev_rel_err = None\n",
    "    ## store bad impr patience/steps before break\n",
    "    patience = 10\n",
    "    bad = 0\n",
    "\n",
    "    ## speed up - binning & less usage of fl\n",
    "    L = Y.shape[0]\n",
    "    if L >= 1000000:\n",
    "        bin_size = 50\n",
    "        fl_every = 5\n",
    "    else:\n",
    "        bin_size = 20\n",
    "        fl_every = 3\n",
    "    \n",
    "    for n in range(num_iter):\n",
    "        if n % 50 == 0:\n",
    "            print('\\n', f'==== Starting iteration {n} ====')\n",
    "        # Update W\n",
    "        # $W \\leftarrow Y H^T (H H^T + D)^{-1}$\n",
    "        A = (H @ H.T + D) #(k,k)\n",
    "        B = (Y @ H.T)     #(nrow,k)\n",
    "        \n",
    "        # W = B @ np.linalg.inv(A) # slow indicated by GPT\n",
    "        W = np.linalg.solve(A.T, B.T).T.astype(np.float32, copy=False)\n",
    "        # np.linalg.solve() above is the same as A^T @ X = B^T \n",
    "        # -> X = (A^T)^(-1) @ B^T \n",
    "        # -> Xt= ((A^T)^(-1) @ B^T)^T\n",
    "        #      = B @ inv(A.T).T\n",
    "        #      = B @ inv(A)\n",
    "\n",
    "        # Set negative elements of W to 0\n",
    "        W[W < 0.0] = 0.0\n",
    "\n",
    "        # apply fused lasso\n",
    "        if fl_lambda > 0.0 and (n % fl_every == 0):\n",
    "            for j in range(k): #cols of W\n",
    "                # W[:, j] = fused_lasso(W[:, j], fl_lambda)\n",
    "                W[:, j] = fused_lasso_binned(W[:, j], fl_lambda, bin_size=bin_size)\n",
    "            W[W < 0.0] = 0.0\n",
    "        \n",
    "        # Update H\n",
    "        C = (W.T@W) + D\n",
    "        E = (W.T@Y)\n",
    "        # H = inv(C)@E\n",
    "        H = np.linalg.solve(C, E).astype(np.float32, copy=False)\n",
    "        # C @ X = E\n",
    "        # X = inv(C)@E\n",
    "\n",
    "        # Set negative elements of H to 0\n",
    "        H[H < 0.0] = 0.0\n",
    "\n",
    "        #early stopping?\n",
    "        rel_err = np.linalg.norm(Y - W@H, 'fro') / ynorm #Frobenius norm\n",
    "        if prev_rel_err is None:\n",
    "            impr = np.nan\n",
    "        else:\n",
    "            impr = (prev_rel_err-rel_err) / max(prev_rel_err, 1e-12) #prevent 0 div; we want impr > 0\n",
    "\n",
    "        #log\n",
    "        if n % 50 == 0:\n",
    "            print(f\"rel_err={rel_err:.6f} impr={impr:.3e}\")\n",
    "\n",
    "        #eval\n",
    "        if prev_rel_err is not None and impr <= 1e-6:\n",
    "            bad += 1\n",
    "        else:\n",
    "            bad = 0\n",
    "        \n",
    "        if bad >= patience:\n",
    "            print(f\"Stop: no improvement for {patience} iterations (iter {n})\")\n",
    "            break\n",
    "\n",
    "        if prev_rel_err is not None and impr > 0.0 and impr < tol:\n",
    "            print(f\"Converged at iteration {n}\")\n",
    "            break\n",
    "\n",
    "        #update error\n",
    "        prev_rel_err = rel_err\n",
    "\n",
    "    return W, H\n",
    "\n",
    "\n",
    "########### RUN1 - Hyperparameter Tuning Using Grid Search (comment out later) ###########\n",
    "# k, (num_iter,) l2penalty, and fl_lambda are all hyperparameters that should be tuned to maximize correlation with genes\n",
    "\n",
    "def load_realAnnot(annotation_bw_path, chrom, start, end): \n",
    "    with pyBigWig.open(annotation_bw_path) as bw:\n",
    "        g = bw.values(chrom, start, end, numpy=True)\n",
    "    g = g.astype(np.float32, copy=False)\n",
    "    np.nan_to_num(g, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return g\n",
    "\n",
    "def eval_pearson_corr(a, b):\n",
    "    a = np.asarray(a, dtype=np.float32)\n",
    "    b = np.asarray(b, dtype=np.float32)\n",
    "    if a.shape[0] != b.shape[0]:\n",
    "        raise ValueError(\"Vectors must have the same length\")\n",
    "    \n",
    "    a_bar = a - a.mean()\n",
    "    b_bar = b - b.mean()\n",
    "    sasb = (np.linalg.norm(a_bar) * np.linalg.norm(b_bar)) + 1e-12\n",
    "    r = float(np.dot(a_bar, b_bar) / sasb)\n",
    "    return r\n",
    "\n",
    "def find_maxAbs_pearson_corr(W, g):\n",
    "    best = -1.0\n",
    "    best_feature = -1\n",
    "    for j in range(W.shape[1]):\n",
    "        r = eval_pearson_corr(W[:, j], g)\n",
    "        if abs(r) > best:\n",
    "            best = abs(r)\n",
    "            best_j = j\n",
    "    return best, best_j\n",
    "\n",
    "\n",
    "##### Grid Search + Eval #####\n",
    "g = load_realAnnot('/ihome/hpark/til177/GitHub/cobb2060-2026s/Data_cobb2060/proj2/Annotation_hg18.Gene.bw', args.chromosome_number, args.start_pos, args.end_pos) \n",
    "\n",
    "l2_grid = [1e-6, 1e-4, 1e-2, 1e-1, 1.0]\n",
    "fl_grid = [0.0, 0.1, 0.3, 1.0, 3.0, 10.0]\n",
    "\n",
    "best = (-1.0, None, None)\n",
    "\n",
    "for l2 in l2_grid:\n",
    "    for fl in fl_grid:\n",
    "        W, H = NMF_FL(Y, args.k, num_iter=100, l2penalty=l2, fl_lambda=fl, tol=1e-4)\n",
    "        score, best_j = find_maxAbs_pearson_corr(W, g)\n",
    "        print(f\"l2={l2:g} fl={fl:g} score={score:.4f} best_j={best_j}\")\n",
    "        if score > best[0]:\n",
    "            best = (score, l2, fl)\n",
    "\n",
    "print(\"BEST:\", best)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
